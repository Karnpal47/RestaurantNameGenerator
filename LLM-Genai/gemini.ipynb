{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.27.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (70.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.69.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.6.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.9/390.3 MB 19.6 MB/s eta 0:00:20\n",
      "    --------------------------------------- 8.4/390.3 MB 20.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 12.6/390.3 MB 20.2 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 16.3/390.3 MB 19.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 17.0/390.3 MB 17.1 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 18.1/390.3 MB 14.4 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 19.7/390.3 MB 13.2 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 21.5/390.3 MB 12.7 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 24.1/390.3 MB 12.6 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 27.3/390.3 MB 12.8 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 29.9/390.3 MB 12.7 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 32.5/390.3 MB 12.8 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 35.9/390.3 MB 13.0 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 39.6/390.3 MB 13.3 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 42.7/390.3 MB 13.3 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 45.4/390.3 MB 13.4 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 48.2/390.3 MB 13.4 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 50.3/390.3 MB 13.2 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 52.4/390.3 MB 12.9 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 54.5/390.3 MB 12.8 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 57.1/390.3 MB 12.8 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 60.0/390.3 MB 12.9 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 63.4/390.3 MB 13.0 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 66.1/390.3 MB 13.0 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 67.9/390.3 MB 12.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 70.3/390.3 MB 12.7 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 72.9/390.3 MB 12.8 MB/s eta 0:00:25\n",
      "   ------- -------------------------------- 76.3/390.3 MB 12.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 78.6/390.3 MB 12.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 80.5/390.3 MB 12.7 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 82.8/390.3 MB 12.6 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 85.7/390.3 MB 12.6 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 88.9/390.3 MB 12.7 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 92.3/390.3 MB 12.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 94.6/390.3 MB 12.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 97.0/390.3 MB 12.7 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 99.6/390.3 MB 12.7 MB/s eta 0:00:23\n",
      "   ---------- ---------------------------- 102.5/390.3 MB 12.7 MB/s eta 0:00:23\n",
      "   ---------- ---------------------------- 105.4/390.3 MB 12.7 MB/s eta 0:00:23\n",
      "   ---------- ---------------------------- 108.3/390.3 MB 12.7 MB/s eta 0:00:23\n",
      "   ----------- --------------------------- 111.4/390.3 MB 12.8 MB/s eta 0:00:22\n",
      "   ----------- --------------------------- 113.8/390.3 MB 12.7 MB/s eta 0:00:22\n",
      "   ----------- --------------------------- 115.1/390.3 MB 12.6 MB/s eta 0:00:22\n",
      "   ----------- --------------------------- 116.7/390.3 MB 12.5 MB/s eta 0:00:22\n",
      "   ----------- --------------------------- 119.0/390.3 MB 12.4 MB/s eta 0:00:22\n",
      "   ------------ -------------------------- 121.6/390.3 MB 12.4 MB/s eta 0:00:22\n",
      "   ------------ -------------------------- 123.5/390.3 MB 12.5 MB/s eta 0:00:22\n",
      "   ------------ -------------------------- 125.8/390.3 MB 12.3 MB/s eta 0:00:22\n",
      "   ------------ -------------------------- 128.7/390.3 MB 12.4 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 132.1/390.3 MB 12.4 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 135.3/390.3 MB 12.5 MB/s eta 0:00:21\n",
      "   ------------- ------------------------- 138.4/390.3 MB 12.5 MB/s eta 0:00:21\n",
      "   -------------- ------------------------ 142.1/390.3 MB 12.6 MB/s eta 0:00:20\n",
      "   -------------- ------------------------ 144.2/390.3 MB 12.6 MB/s eta 0:00:20\n",
      "   -------------- ------------------------ 146.0/390.3 MB 12.5 MB/s eta 0:00:20\n",
      "   -------------- ------------------------ 148.1/390.3 MB 12.5 MB/s eta 0:00:20\n",
      "   --------------- ----------------------- 151.0/390.3 MB 12.4 MB/s eta 0:00:20\n",
      "   --------------- ----------------------- 154.1/390.3 MB 12.5 MB/s eta 0:00:19\n",
      "   --------------- ----------------------- 157.5/390.3 MB 12.6 MB/s eta 0:00:19\n",
      "   ---------------- ---------------------- 160.4/390.3 MB 12.6 MB/s eta 0:00:19\n",
      "   ---------------- ---------------------- 162.3/390.3 MB 12.5 MB/s eta 0:00:19\n",
      "   ---------------- ---------------------- 164.4/390.3 MB 12.5 MB/s eta 0:00:19\n",
      "   ---------------- ---------------------- 167.0/390.3 MB 12.5 MB/s eta 0:00:18\n",
      "   ----------------- --------------------- 170.1/390.3 MB 12.5 MB/s eta 0:00:18\n",
      "   ----------------- --------------------- 173.0/390.3 MB 12.5 MB/s eta 0:00:18\n",
      "   ----------------- --------------------- 175.6/390.3 MB 12.5 MB/s eta 0:00:18\n",
      "   ----------------- --------------------- 176.9/390.3 MB 12.4 MB/s eta 0:00:18\n",
      "   ----------------- --------------------- 178.8/390.3 MB 12.4 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 181.4/390.3 MB 12.4 MB/s eta 0:00:17\n",
      "   ------------------ -------------------- 184.5/390.3 MB 12.4 MB/s eta 0:00:17\n",
      "   ------------------ -------------------- 188.0/390.3 MB 12.4 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 191.1/390.3 MB 12.5 MB/s eta 0:00:16\n",
      "   ------------------- ------------------- 193.2/390.3 MB 12.4 MB/s eta 0:00:16\n",
      "   ------------------- ------------------- 195.3/390.3 MB 12.4 MB/s eta 0:00:16\n",
      "   ------------------- ------------------- 197.9/390.3 MB 12.4 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 201.1/390.3 MB 12.4 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 204.2/390.3 MB 12.5 MB/s eta 0:00:15\n",
      "   -------------------- ------------------ 206.3/390.3 MB 12.4 MB/s eta 0:00:15\n",
      "   -------------------- ------------------ 209.2/390.3 MB 12.4 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 212.3/390.3 MB 12.5 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 215.0/390.3 MB 12.4 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 217.3/390.3 MB 12.4 MB/s eta 0:00:14\n",
      "   --------------------- ----------------- 219.4/390.3 MB 12.4 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 221.8/390.3 MB 12.4 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 224.7/390.3 MB 12.4 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 228.1/390.3 MB 12.4 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 230.4/390.3 MB 12.4 MB/s eta 0:00:13\n",
      "   ----------------------- --------------- 231.7/390.3 MB 12.4 MB/s eta 0:00:13\n",
      "   ----------------------- --------------- 233.6/390.3 MB 12.3 MB/s eta 0:00:13\n",
      "   ----------------------- --------------- 235.9/390.3 MB 12.3 MB/s eta 0:00:13\n",
      "   ----------------------- --------------- 238.8/390.3 MB 12.3 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 242.0/390.3 MB 12.3 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 245.4/390.3 MB 12.4 MB/s eta 0:00:12\n",
      "   ------------------------ -------------- 249.3/390.3 MB 12.4 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 251.9/390.3 MB 12.4 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 253.5/390.3 MB 12.4 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 255.3/390.3 MB 12.3 MB/s eta 0:00:11\n",
      "   ------------------------- ------------- 257.9/390.3 MB 12.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 260.8/390.3 MB 12.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 264.2/390.3 MB 12.3 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 267.4/390.3 MB 12.3 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 270.5/390.3 MB 12.3 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 272.4/390.3 MB 12.2 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 274.2/390.3 MB 12.1 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 276.6/390.3 MB 12.0 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 279.2/390.3 MB 12.1 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 282.3/390.3 MB 12.3 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 286.0/390.3 MB 12.4 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 288.6/390.3 MB 12.4 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 290.7/390.3 MB 12.3 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 293.3/390.3 MB 12.3 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 296.0/390.3 MB 12.3 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 299.4/390.3 MB 12.3 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 301.2/390.3 MB 12.2 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 302.5/390.3 MB 12.2 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 304.6/390.3 MB 12.1 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 307.2/390.3 MB 12.1 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 310.4/390.3 MB 12.1 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 313.8/390.3 MB 12.2 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 317.5/390.3 MB 12.3 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 320.1/390.3 MB 12.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 321.7/390.3 MB 12.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 323.5/390.3 MB 12.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 326.1/390.3 MB 12.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 329.0/390.3 MB 12.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 332.1/390.3 MB 12.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 335.3/390.3 MB 12.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 337.9/390.3 MB 12.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 340.0/390.3 MB 12.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 342.4/390.3 MB 12.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 345.5/390.3 MB 12.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 348.9/390.3 MB 12.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 350.7/390.3 MB 12.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 352.6/390.3 MB 12.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 354.9/390.3 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 357.8/390.3 MB 12.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 361.2/390.3 MB 12.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 363.6/390.3 MB 12.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 366.5/390.3 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 369.1/390.3 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 372.2/390.3 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 374.6/390.3 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 376.4/390.3 MB 12.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 379.3/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.5/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  387.2/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.3/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.69.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 2.6/4.4 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading h5py-3.12.1-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.9/3.0 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 13.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 13.3 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.6/26.4 MB 18.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.1/26.4 MB 18.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 18.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.3/26.4 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.4/26.4 MB 14.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.4 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 11.8 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 14.6 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, astunparse, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.12.23 gast-0.6.0 google-pasta-0.2.0 grpcio-1.69.0 h5py-3.12.1 keras-3.8.0 libclang-18.1.1 markdown-3.7 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=gpt2-small. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(gpt2-small, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load a pre-trained language model (e.g., a smaller version like 'gpt2-small')\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2-small\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate text\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want to make an Indian hotel. Suggest a fancy name for it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=gpt2-small. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(gpt2-small, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load a pre-trained language model (e.g., a smaller version like 'gpt2-small')\n",
    "model_name = \"gpt2-small\" \n",
    "model = tf.keras.models.load_model(model_name)\n",
    "\n",
    "# Generate text\n",
    "prompt = \"I want to make an Indian hotel. Suggest a fancy name for it.\"\n",
    "input_ids = model.tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "\n",
    "# Generate text using the model\n",
    "generated_ids = model.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Decode the generated IDs to text\n",
    "generated_text = model.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[gpt2] in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.48.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from transformers[gpt2]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[gpt2]) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[gpt2]) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[gpt2]) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers[gpt2]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[gpt2]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[gpt2]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[gpt2]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[gpt2]) (2024.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: transformers 4.48.0 does not provide the extra 'gpt2'\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[\"gpt2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0c6d9a72a14c34b533534ed92e1c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3355a15f4584c51b5a82230aa2a1aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid device string: '/job:localhost/replica:0/task:0/device:CPU:0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m hotel_name \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_hotel_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated hotel name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhotel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 30\u001b[0m, in \u001b[0;36mgenerate_hotel_name\u001b[1;34m(model_name, prompt, max_length, num_beams, no_repeat_ngram_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError generating name\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m     29\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py:2033\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2030\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m inputs_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2032\u001b[0m device \u001b[38;5;241m=\u001b[39m inputs_tensor\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m-> 2033\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_special_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_has_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2035\u001b[0m \u001b[38;5;66;03m# decoder-only models must use left-padding for batched generation.\u001b[39;00m\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m   2037\u001b[0m     \u001b[38;5;66;03m# If `input_ids` was given, check if the last id in any sequence is `pad_token_id`\u001b[39;00m\n\u001b[0;32m   2038\u001b[0m     \u001b[38;5;66;03m# Note: If using, `inputs_embeds` this check does not work, because we want to be more hands-off.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py:1848\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_special_tokens\u001b[1;34m(self, generation_config, kwargs_has_attention_mask, device)\u001b[0m\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m token\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(token, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m-> 1848\u001b[0m bos_token_tensor \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_or_none\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbos_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1849\u001b[0m eos_token_tensor \u001b[38;5;241m=\u001b[39m _tensor_or_none(generation_config\u001b[38;5;241m.\u001b[39meos_token_id, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m   1850\u001b[0m pad_token_tensor \u001b[38;5;241m=\u001b[39m _tensor_or_none(generation_config\u001b[38;5;241m.\u001b[39mpad_token_id, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py:1846\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_special_tokens.<locals>._tensor_or_none\u001b[1;34m(token, device)\u001b[0m\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(token, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m token\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m-> 1846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Invalid device string: '/job:localhost/replica:0/task:0/device:CPU:0'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def generate_hotel_name(model_name=\"gpt2\", prompt=\"I want to make an Indian hotel. Suggest a fancy name for it.\", \n",
    "                       max_length=50, num_beams=5, no_repeat_ngram_size=2):\n",
    "  \"\"\"\n",
    "  Generates a fancy name for an Indian hotel using a pre-trained language model.\n",
    "\n",
    "  Args:\n",
    "    model_name: The name of the pre-trained language model. Defaults to \"gpt2\".\n",
    "    prompt: The input prompt for the model. \n",
    "    max_length: The maximum length of the generated text.\n",
    "    num_beams: The number of beams for beam search decoding.\n",
    "    no_repeat_ngram_size: The size of the n-grams to prevent repetition.\n",
    "\n",
    "  Returns:\n",
    "    The generated hotel name.\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    # Load the tokenizer and model using Transformers\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name) \n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    return \"Error generating name\" \n",
    "\n",
    "  input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
    "  generated_ids = model.generate(\n",
    "      input_ids, \n",
    "      max_length=max_length, \n",
    "      num_beams=num_beams, \n",
    "      no_repeat_ngram_size=no_repeat_ngram_size, \n",
    "      early_stopping=True\n",
    "  )\n",
    "  generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "  return generated_text\n",
    "\n",
    "# Example usage\n",
    "hotel_name = generate_hotel_name()\n",
    "print(f\"Generated hotel name: {hotel_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
